import cv2
import numpy as np
from scipy.spatial import distance
from skimage.measure import label, regionprops

def undistort_fisheye(image, strength=0.5, zoom=1.0, balance=0.0):
    """
    Improved fisheye undistortion with area preservation and quality maintenance.
    
    Args:
        image: Input fisheye image (BGR format)
        strength: Distortion correction strength (0.0 to 1.0)
        zoom: Zoom factor (0.8 to 1.5) to adjust output crop
        balance: Balance between linear and nonlinear correction (0.0 to 1.0)
    Returns:
        Undistorted image with preserved area and quality
    """
    if image is None:
        raise ValueError("Input image is None")
        
    h, w = image.shape[:2]
    
    # Create normalized pixel coordinates
    x = (np.arange(w, dtype=np.float32) - w * 0.5) / (w * 0.5)
    y = (np.arange(h, dtype=np.float32) - h * 0.5) / (h * 0.5)
    xx, yy = np.meshgrid(x, y)
    
    # Calculate radial distance
    r = np.sqrt(xx**2 + yy**2)
    theta = np.arctan(r)  # More accurate than simple multiplication
    
    # Avoid division by zero at center
    mask = r > 1e-8
    inv_r = np.zeros_like(r)
    inv_r[mask] = 1.0 / r[mask]
    
    # Enhanced correction formula with area preservation
    correction = (1.0 - balance) * np.sin(theta * strength) + balance * (theta * strength)
    
    # Area preservation adjustment
    area_factor = 1.0 / (1.0 + 0.2 * strength)  # Compensate for area changes
    correction *= area_factor
    
    # Apply correction
    new_x = xx * inv_r * correction
    new_y = yy * inv_r * correction
    
    # Apply zoom and center with adjusted scaling for quality preservation
    zoom_factor = zoom * (1.0 - 0.1 * strength)  # Compensate for edge stretching
    new_x = new_x * zoom_factor * (w * 0.5) + (w * 0.5)
    new_y = new_y * zoom_factor * (h * 0.5) + (h * 0.5)
    
    # High-quality remapping with Lanczos interpolation
    undistorted = cv2.remap(
        image, 
        new_x.astype(np.float32), 
        new_y.astype(np.float32), 
        interpolation=cv2.INTER_LANCZOS4,
        borderMode=cv2.BORDER_REFLECT101  # Better edge handling
    )
    
    return undistorted

def dimensional_analysis(image, reference_length_pixels, reference_length_units):
    """
    Perform dimensional analysis on objects in the image.
    
    Args:
        image: Input image (BGR format)
        reference_length_pixels: Known length in pixels
        reference_length_units: Actual length in real-world units
    Returns:
        Dictionary containing measurements of detected objects
    """
    if image is None:
        raise ValueError("Input image is None")
        
    # Convert to grayscale and enhance contrast
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(gray, 255, 
                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY_INV, 11, 2)
    
    # Remove small noise
    kernel = np.ones((3,3), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    
    # Find contours
    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Calculate pixel-to-unit conversion factor
    pixel_to_unit = reference_length_units / reference_length_pixels
    
    measurements = []
    min_contour_area = 100  # Minimum area to consider as valid object
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < min_contour_area:
            continue
            
        # Fit rotated rectangle
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        box = np.int0(box)
        
        # Calculate dimensions
        width_px = min(rect[1])
        height_px = max(rect[1])
        
        # Convert to real units
        width_units = width_px * pixel_to_unit
        height_units = height_px * pixel_to_unit
        area_units = area * (pixel_to_unit ** 2)
        
        # Calculate perimeter
        perimeter_px = cv2.arcLength(contour, True)
        perimeter_units = perimeter_px * pixel_to_unit
        
        # Store measurements
        measurements.append({
            'width_px': width_px,
            'height_px': height_px,
            'width_units': width_units,
            'height_units': height_units,
            'area_px': area,
            'area_units': area_units,
            'perimeter_px': perimeter_px,
            'perimeter_units': perimeter_units,
            'aspect_ratio': width_px / height_px,
            'centroid': rect[0]
        })
    
    return measurements

def draw_measurements(image, measurements):
    """
    Draw measurements on the image.
    
    Args:
        image: Input image
        measurements: List of measurement dictionaries
    Returns:
        Image with measurements drawn
    """
    output = image.copy()
    
    for meas in measurements:
        center = tuple(map(int, meas['centroid']))
        
        # Draw bounding box
        cv2.drawContours(output, [meas['bounding_box']], 0, (0, 255, 0), 2)
        
        # Draw dimensions
        cv2.putText(output, f"W: {meas['width_units']:.2f} units", 
                   (center[0]+20, center[1]-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"H: {meas['height_units']:.2f} units", 
                   (center[0]+20, center[1]+0), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"A: {meas['area_units']:.2f} sq.units", 
                   (center[0]+20, center[1]+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    return output

# Example usage with error handling
try:
    # Load image
    image = cv2.imread("fisheye_input.jpg")
    if image is None:
        raise FileNotFoundError("Could not load image")
    
    # Undistort with optimized parameters for area/quality preservation
    undistorted = undistort_fisheye(image, strength=0.6, zoom=1.05, balance=0.3)
    
    # Perform dimensional analysis (requires a known reference measurement)
    # For example, if a 100px object in the image is known to be 10cm in real life:
    reference_length_pixels = 100  # Must be measured from the image
    reference_length_units = 10.0  # In centimeters (or any unit)
    
    measurements = dimensional_analysis(undistorted, reference_length_pixels, reference_length_units)
    
    # Draw measurements on the image
    measured_image = draw_measurements(undistorted, measurements)
    
    # Save results
    cv2.imwrite("undistorted_output.jpg", undistorted)
    cv2.imwrite("measured_output.jpg", measured_image)
    
    # Print measurements
    print("Measurement results:")
    for i, meas in enumerate(measurements):
        print(f"Object {i+1}:")
        print(f"  Width: {meas['width_units']:.2f} units")
        print(f"  Height: {meas['height_units']:.2f} units")
        print(f"  Area: {meas['area_units']:.2f} square units")
        print(f"  Perimeter: {meas['perimeter_units']:.2f} units")
        print(f"  Aspect ratio: {meas['aspect_ratio']:.2f}")
    
    print("Processing completed successfully")
    
except Exception as e:
    print(f"Error: {str(e)}")









def dimensional_analysis(image, reference_length_pixels, reference_length_units):
    """
    Perform dimensional analysis on objects in the image.
    
    Args:
        image: Input image (BGR format)
        reference_length_pixels: Known length in pixels
        reference_length_units: Actual length in real-world units
    Returns:
        Dictionary containing measurements of detected objects
    """
    if image is None:
        raise ValueError("Input image is None")
        
    # Convert to grayscale and enhance contrast
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(gray, 255, 
                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY_INV, 11, 2)
    
    # Remove small noise
    kernel = np.ones((3,3), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    
    # Find contours
    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Calculate pixel-to-unit conversion factor
    pixel_to_unit = reference_length_units / reference_length_pixels
    
    measurements = []
    min_contour_area = 100  # Minimum area to consider as valid object
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < min_contour_area:
            continue
            
        # Fit rotated rectangle
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        box = np.int32(box)  # Convert to integers for drawing
        
        # Calculate dimensions
        width_px = min(rect[1])
        height_px = max(rect[1])
        
        # Convert to real units
        width_units = width_px * pixel_to_unit
        height_units = height_px * pixel_to_unit
        area_units = area * (pixel_to_unit ** 2)
        
        # Calculate perimeter
        perimeter_px = cv2.arcLength(contour, True)
        perimeter_units = perimeter_px * pixel_to_unit
        
        # Store measurements including bounding box
        measurements.append({
            'width_px': width_px,
            'height_px': height_px,
            'width_units': width_units,
            'height_units': height_units,
            'area_px': area,
            'area_units': area_units,
            'perimeter_px': perimeter_px,
            'perimeter_units': perimeter_units,
            'aspect_ratio': width_px / height_px,
            'centroid': rect[0],
            'bounding_box': box  # Add the bounding box points
        })
    
    return measurements

def draw_measurements(image, measurements):
    """
    Draw measurements on the image.
    
    Args:
        image: Input image
        measurements: List of measurement dictionaries
    Returns:
        Image with measurements drawn
    """
    output = image.copy()
    
    for meas in measurements:
        center = tuple(map(int, meas['centroid']))
        
        # Draw bounding box (now properly defined)
        cv2.drawContours(output, [meas['bounding_box']], 0, (0, 255, 0), 2)
        
        # Draw dimensions
        cv2.putText(output, f"W: {meas['width_units']:.2f} units", 
                   (center[0]+20, center[1]-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"H: {meas['height_units']:.2f} units", 
                   (center[0]+20, center[1]+0), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"A: {meas['area_units']:.2f} sq.units", 
                   (center[0]+20, center[1]+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    return output








# Perform dimensional analysis (requires a known reference measurement)
reference_length_pixels = 100  # Measure a known object in the image (in pixels)
reference_length_units = 10.0  # The actual length of that object (in cm, inches, etc.)

measurements = dimensional_analysis(undistorted, reference_length_pixels, reference_length_units)

# Draw measurements on the image
measured_image = draw_measurements(undistorted, measurements)

# Display or save the result
cv2.imshow("Measurements", measured_image)
cv2.waitKey(0)
cv2.destroyAllWindows()






def undistort_fisheye_improved(image, strength=0.5, zoom=1.0, balance=0.3, output_shape=None):
    """
    Advanced fisheye undistortion with better quality preservation.
    
    Args:
        image: Input fisheye image (BGR format)
        strength: Distortion correction strength (0.0 to 1.0)
        zoom: Zoom factor (0.8 to 1.5) to adjust output crop
        balance: Balance between linear and nonlinear correction (0.0 to 1.0)
        output_shape: Optional (width, height) tuple for output size
    Returns:
        Undistorted image with preserved quality
    """
    if image is None:
        raise ValueError("Input image is None")
        
    h, w = image.shape[:2]
    
    # Use specified output shape or maintain input dimensions
    if output_shape:
        out_h, out_w = output_shape
    else:
        out_h, out_w = h, w
    
    # Create normalized pixel coordinates in output image space
    x = (np.arange(out_w, dtype=np.float32) - out_w * 0.5
    y = (np.arange(out_h, dtype=np.float32) - out_h * 0.5
    xx, yy = np.meshgrid(x, y)
    
    # Normalize coordinates to [-1, 1] range
    xx_norm = xx / (out_w * 0.5)
    yy_norm = yy / (out_h * 0.5)
    
    # Calculate radial distance with protection against division by zero
    r = np.sqrt(xx_norm**2 + yy_norm**2)
    r = np.clip(r, 1e-8, 1.0)  # Avoid division by zero and extreme values
    
    # Advanced distortion correction formula
    theta = r * (1.0 - strength * 0.5)  # Base correction
    theta = np.where(r > 0.5, 
                    theta * (1.0 + balance * (r - 0.5) * 2),  # Stronger correction at edges
                    theta * (1.0 - balance * (0.5 - r) * 2))  # Gentler correction at center
    
    # Apply zoom factor with edge protection
    zoom_factor = zoom * (1.0 + 0.2 * strength)  # Compensate for edge stretching
    new_x = xx_norm * theta * zoom_factor * (w * 0.5) + (w * 0.5)
    new_y = yy_norm * theta * zoom_factor * (h * 0.5) + (h * 0.5)
    
    # High-quality remapping with multiple interpolation methods
    undistorted = cv2.remap(
        image, 
        new_x.astype(np.float32), 
        new_y.astype(np.float32), 
        interpolation=cv2.INTER_LANCZOS4,
        borderMode=cv2.BORDER_REFLECT101
    )
    
    # Post-processing to enhance quality
    undistorted = cv2.detailEnhance(undistorted, sigma_s=10, sigma_r=0.15)
    
    return undistorted
























Key Objectives:
Undistort using an approximate fisheye model (e.g. stereographic or equisolid).

Preserve resolution and field of view as much as possible.

Enable accurate dimensional analysis later using a known real-world reference object (like a ruler in the image).

🧠 Best Strategy Overview:
Use stereographic projection for natural undistortion.

Use a manually specified FOV.

Normalize coordinates to apply distortion correction.

Let the user pass a known object length (e.g., a line in pixels and its real-world length in cm) to calculate pixels-per-cm.

🧾 Code: Undistortion with Post-Hoc Scaling
python
Copy
Edit
import cv2
import numpy as np

def undistort_fisheye_approx(image, model="stereographic", fov_deg=180, zoom=1.0):
    """
    Undistort a fisheye image using an approximate model (stereographic, equisolid, etc.).
    
    Args:
        image (np.ndarray): Input fisheye image (BGR)
        model (str): One of 'stereographic', 'equisolid', 'equidistant'
        fov_deg (float): Horizontal field of view in degrees
        zoom (float): Zoom factor (1.0 = keep original FOV)
    
    Returns:
        Undistorted image (same size), remap_x, remap_y
    """
    h, w = image.shape[:2]
    cx, cy = w / 2, h / 2

    # Normalize coordinates to [-1, 1]
    x = (np.arange(w, dtype=np.float32) - cx) / cx
    y = (np.arange(h, dtype=np.float32) - cy) / cy
    xx, yy = np.meshgrid(x, y)
    r = np.sqrt(xx**2 + yy**2)

    # Convert to angle theta
    theta = r * np.radians(fov_deg / 2)

    # Apply inverse projection model
    if model == "stereographic":
        r_corrected = 2 * np.tan(theta / 2)
    elif model == "equisolid":
        r_corrected = 2 * np.sin(theta / 2)
    elif model == "equidistant":
        r_corrected = theta
    else:
        raise ValueError("Unsupported model: choose stereographic, equisolid, or equidistant")

    # Avoid division by zero
    scale = np.where(r > 1e-8, r_corrected / r, 1.0) * zoom

    map_x = (xx * scale * cx + cx).astype(np.float32)
    map_y = (yy * scale * cy + cy).astype(np.float32)

    # Remap using high-quality interpolation
    undistorted = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LANCZOS4, borderMode=cv2.BORDER_REFLECT101)
    return undistorted, map_x, map_y
📐 Step 2: Dimensional Analysis Using Reference Object
python
Copy
Edit
def pixels_per_cm(reference_pixel_length, real_length_cm):
    """
    Calculate pixels per cm from reference object.
    
    Args:
        reference_pixel_length (float): length in pixels
        real_length_cm (float): known real-world length in cm
        
    Returns:
        scale: pixels per cm
    """
    return reference_pixel_length / real_length_cm

def measure_distance(pt1, pt2, px_per_cm):
    """
    Measure real-world distance between two points in cm.
    
    Args:
        pt1, pt2: (x, y) coordinates in pixels
        px_per_cm: pixels per cm scaling factor
        
    Returns:
        distance in cm
    """
    px_dist = np.linalg.norm(np.array(pt1) - np.array(pt2))
    return px_dist / px_per_cm
🛠️ How to Use This in Practice
1. Capture Image With Known Object
Place a ruler or object of known size in the image.

2. Run Undistortion
python
Copy
Edit
undistorted, _, _ = undistort_fisheye_approx(image, model="stereographic", fov_deg=180)
3. Mark Reference Points
Use OpenCV cv2.setMouseCallback to mark two endpoints on the known object, or hardcode pixel coordinates.

python
Copy
Edit
reference_length_px = 250  # e.g. pixel distance between 10 cm object
px_per_cm = pixels_per_cm(reference_length_px, 10)
4. Measure in Image
python
Copy
Edit
real_distance = measure_distance((x1, y1), (x2, y2), px_per_cm)
print(f"Measured: {real_distance:.2f} cm")
✅ Why This Works for Your Case
Preserves original resolution and dimensions ✅

Undistortion removes major fisheye artifacts ✅

Field of view remains wide enough for coverage ✅

Dimensional accuracy is achieved via manual calibration (pixels-per-cm) ✅

Would you like a full working GUI tool where you can:

Select two points on the image

Enter known real-world length

Get real-world measurements from undistorted image?

I can write that for you next.








