setIsModalOpen(true)}>Take Photo</button>

      {isModalOpen && (
        <div style={styles.modal}>
          <div style={styles.modalContent}>
            <h2>Camera Capture</h2>

            {!imageBase64 ? (
              <>
                <video
                  ref={videoRef}
                  autoPlay
                  playsInline
                  muted
                  style={{ width: '100%', height: 'auto', backgroundColor: '#000' }}
                />
                <button onClick={takePhoto} disabled={!isCameraReady}>
                  {isCameraReady ? 'Capture' : 'Loading...'}
                </button>
                <button onClick={() => setIsModalOpen(false)}>Close</button>
              </>
            ) : (
              <>
                <img src={imageBase64} alt="Captured" style={{ width: '100%', height: 'auto' }} />
                <button onClick={retakePhoto}>Retake</button>
                <button onClick={savePhoto}>Save</button>
              </>
            )}
          </div>
        </div>
      )}
    </div>
  );
};

const styles: { [key: string]: React.CSSProperties } = {
  modal: {
    position: 'fixed',
    top: 0,
    left: 0,
    width: '100vw',
    height: '100vh',
    backgroundColor: 'rgba(0,0,0,0.7)',
    display: 'flex',
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 9999,
  },
  modalContent: {
    backgroundColor: '#fff',
    padding: '20px',
    borderRadius: '8px',
    maxWidth: '400px',
    width: '90%',
    textAlign: 'center',
  },
};

export default CameraCapture;






const [isModalOpen, setIsModalOpen] = useState(false);
  const [isCameraReady, setIsCameraReady] = useState(false);
  const [imageBase64, setImageBase64] = useState<string | null>(null);
  const videoRef = useRef<HTMLVideoElement | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  // Start or stop camera based on modal state
  useEffect(() => {
    if (isModalOpen) {
      const startCamera = async () => {
        try {
          const stream = await navigator.mediaDevices.getUserMedia({ video: true });
          if (videoRef.current) {
            videoRef.current.srcObject = stream;
            await videoRef.current.play();
          }
          streamRef.current = stream;
          setIsCameraReady(true);
        } catch (err) {
          alert('Error accessing camera: ' + (err as Error).message);
        }
      };
      startCamera();
    } else {
      // Stop camera when modal closes
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
        streamRef.current = null;
        setIsCameraReady(false);
      }
      setImageBase64(null); // Clear any captured image
    }
  }, [isModalOpen]);

  const takePhoto = () => {
    if (!isCameraReady) {
      alert('Camera not ready yet!');
      return;
    }

    const video = videoRef.current;
    if (!video) return;

    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    if (!ctx) {
      alert('Error creating canvas context');
      return;
    }

    ctx.drawImage(video, 0, 0);
    const base64 = canvas.toDataURL('image/jpeg');
    setImageBase64(base64);
  };

  const savePhoto = () => {
    if (imageBase64) {
      localStorage.setItem('capturedPhoto', imageBase64);
      alert('Photo saved to local storage!');
      setIsModalOpen(false);
    }
  };

  const retakePhoto = () => {
    setImageBase64(null);
    // Camera remains active, so no need to restart
  };

  const getImageBase64 = (imagePath) => {
  return new Promise((resolve, reject) => {
    // Fetch the image file
    fetch(imagePath)
      .then(response => response.blob())
      .then(blob => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
      })
      .catch(reject);
  });
};

// Usage example
const imagePath = require('./deviation/your-image.jpg').default;

getImageBase64(imagePath)
  .then(base64 => {
    console.log('Base64 string:', base64);
    // Use the base64 string as needed
  })
  .catch(error => {
    console.error('Error converting image to base64:', error);
  });







// utils/getBase64.ts
export const getImageBase64 = async (imageUrl: string): Promise<string> => {
  const response = await fetch(imageUrl);
  const blob = await response.blob();

  return new Promise<string>((resolve, reject) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      if (typeof reader.result === 'string') {
        resolve(reader.result);
      } else {
        reject(new Error('Failed to convert image to Base64'));
      }
    };
    reader.onerror = reject;
    reader.readAsDataURL(blob);
  });
};
// Add this to global.d.ts
declare class MediaStreamTrackProcessor {
  constructor(options: { track: MediaStreamTrack });
  readable: ReadableStream<VideoFrame>;
}

declare class MediaStreamTrackGenerator {
  constructor(options: { kind: 'video' | 'audio' });
  writable: WritableStream<VideoFrame>;
}

// Updated processVideoStream with fallback
const processVideoStream = async (originalStream: MediaStream): Promise<MediaStream> => {
  const videoTrack = originalStream.getVideoTracks()[0];
  
  if (!videoTrack) {
    throw new Error("No video track found");
  }

  if (typeof MediaStreamTrackProcessor !== 'undefined' && 
      typeof MediaStreamTrackGenerator !== 'undefined') {
    // Use Insertable Streams API if available
    const processor = new MediaStreamTrackProcessor({ track: videoTrack });
    const generator = new MediaStreamTrackGenerator({ kind: 'video' });
    
    const transformer = new TransformStream({
      async transform(frame: VideoFrame, controller) {
        const deviation = await getDeviationForFrame(frame);
        if (deviation < YOUR_THRESHOLD) {
          controller.enqueue(frame);
        } else {
          frame.close();
        }
      }
    });
    
    processor.readable.pipeThrough(transformer).pipeTo(generator.writable);
    return new MediaStream([generator]);
  } else {
    // Fallback to Canvas
    return fallbackCanvasProcessing(originalStream);
  }
};




