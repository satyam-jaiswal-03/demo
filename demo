import cv2
import numpy as np
from scipy.spatial import distance
from skimage.measure import label, regionprops

def undistort_fisheye(image, strength=0.5, zoom=1.0, balance=0.0):
    """
    Improved fisheye undistortion with area preservation and quality maintenance.
    
    Args:
        image: Input fisheye image (BGR format)
        strength: Distortion correction strength (0.0 to 1.0)
        zoom: Zoom factor (0.8 to 1.5) to adjust output crop
        balance: Balance between linear and nonlinear correction (0.0 to 1.0)
    Returns:
        Undistorted image with preserved area and quality
    """
    if image is None:
        raise ValueError("Input image is None")
        
    h, w = image.shape[:2]
    
    # Create normalized pixel coordinates
    x = (np.arange(w, dtype=np.float32) - w * 0.5) / (w * 0.5)
    y = (np.arange(h, dtype=np.float32) - h * 0.5) / (h * 0.5)
    xx, yy = np.meshgrid(x, y)
    
    # Calculate radial distance
    r = np.sqrt(xx**2 + yy**2)
    theta = np.arctan(r)  # More accurate than simple multiplication
    
    # Avoid division by zero at center
    mask = r > 1e-8
    inv_r = np.zeros_like(r)
    inv_r[mask] = 1.0 / r[mask]
    
    # Enhanced correction formula with area preservation
    correction = (1.0 - balance) * np.sin(theta * strength) + balance * (theta * strength)
    
    # Area preservation adjustment
    area_factor = 1.0 / (1.0 + 0.2 * strength)  # Compensate for area changes
    correction *= area_factor
    
    # Apply correction
    new_x = xx * inv_r * correction
    new_y = yy * inv_r * correction
    
    # Apply zoom and center with adjusted scaling for quality preservation
    zoom_factor = zoom * (1.0 - 0.1 * strength)  # Compensate for edge stretching
    new_x = new_x * zoom_factor * (w * 0.5) + (w * 0.5)
    new_y = new_y * zoom_factor * (h * 0.5) + (h * 0.5)
    
    # High-quality remapping with Lanczos interpolation
    undistorted = cv2.remap(
        image, 
        new_x.astype(np.float32), 
        new_y.astype(np.float32), 
        interpolation=cv2.INTER_LANCZOS4,
        borderMode=cv2.BORDER_REFLECT101  # Better edge handling
    )
    
    return undistorted

def dimensional_analysis(image, reference_length_pixels, reference_length_units):
    """
    Perform dimensional analysis on objects in the image.
    
    Args:
        image: Input image (BGR format)
        reference_length_pixels: Known length in pixels
        reference_length_units: Actual length in real-world units
    Returns:
        Dictionary containing measurements of detected objects
    """
    if image is None:
        raise ValueError("Input image is None")
        
    # Convert to grayscale and enhance contrast
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(gray, 255, 
                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY_INV, 11, 2)
    
    # Remove small noise
    kernel = np.ones((3,3), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    
    # Find contours
    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Calculate pixel-to-unit conversion factor
    pixel_to_unit = reference_length_units / reference_length_pixels
    
    measurements = []
    min_contour_area = 100  # Minimum area to consider as valid object
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < min_contour_area:
            continue
            
        # Fit rotated rectangle
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        box = np.int0(box)
        
        # Calculate dimensions
        width_px = min(rect[1])
        height_px = max(rect[1])
        
        # Convert to real units
        width_units = width_px * pixel_to_unit
        height_units = height_px * pixel_to_unit
        area_units = area * (pixel_to_unit ** 2)
        
        # Calculate perimeter
        perimeter_px = cv2.arcLength(contour, True)
        perimeter_units = perimeter_px * pixel_to_unit
        
        # Store measurements
        measurements.append({
            'width_px': width_px,
            'height_px': height_px,
            'width_units': width_units,
            'height_units': height_units,
            'area_px': area,
            'area_units': area_units,
            'perimeter_px': perimeter_px,
            'perimeter_units': perimeter_units,
            'aspect_ratio': width_px / height_px,
            'centroid': rect[0]
        })
    
    return measurements

def draw_measurements(image, measurements):
    """
    Draw measurements on the image.
    
    Args:
        image: Input image
        measurements: List of measurement dictionaries
    Returns:
        Image with measurements drawn
    """
    output = image.copy()
    
    for meas in measurements:
        center = tuple(map(int, meas['centroid']))
        
        # Draw bounding box
        cv2.drawContours(output, [meas['bounding_box']], 0, (0, 255, 0), 2)
        
        # Draw dimensions
        cv2.putText(output, f"W: {meas['width_units']:.2f} units", 
                   (center[0]+20, center[1]-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"H: {meas['height_units']:.2f} units", 
                   (center[0]+20, center[1]+0), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"A: {meas['area_units']:.2f} sq.units", 
                   (center[0]+20, center[1]+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    return output

# Example usage with error handling
try:
    # Load image
    image = cv2.imread("fisheye_input.jpg")
    if image is None:
        raise FileNotFoundError("Could not load image")
    
    # Undistort with optimized parameters for area/quality preservation
    undistorted = undistort_fisheye(image, strength=0.6, zoom=1.05, balance=0.3)
    
    # Perform dimensional analysis (requires a known reference measurement)
    # For example, if a 100px object in the image is known to be 10cm in real life:
    reference_length_pixels = 100  # Must be measured from the image
    reference_length_units = 10.0  # In centimeters (or any unit)
    
    measurements = dimensional_analysis(undistorted, reference_length_pixels, reference_length_units)
    
    # Draw measurements on the image
    measured_image = draw_measurements(undistorted, measurements)
    
    # Save results
    cv2.imwrite("undistorted_output.jpg", undistorted)
    cv2.imwrite("measured_output.jpg", measured_image)
    
    # Print measurements
    print("Measurement results:")
    for i, meas in enumerate(measurements):
        print(f"Object {i+1}:")
        print(f"  Width: {meas['width_units']:.2f} units")
        print(f"  Height: {meas['height_units']:.2f} units")
        print(f"  Area: {meas['area_units']:.2f} square units")
        print(f"  Perimeter: {meas['perimeter_units']:.2f} units")
        print(f"  Aspect ratio: {meas['aspect_ratio']:.2f}")
    
    print("Processing completed successfully")
    
except Exception as e:
    print(f"Error: {str(e)}")









def dimensional_analysis(image, reference_length_pixels, reference_length_units):
    """
    Perform dimensional analysis on objects in the image.
    
    Args:
        image: Input image (BGR format)
        reference_length_pixels: Known length in pixels
        reference_length_units: Actual length in real-world units
    Returns:
        Dictionary containing measurements of detected objects
    """
    if image is None:
        raise ValueError("Input image is None")
        
    # Convert to grayscale and enhance contrast
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    
    # Apply adaptive thresholding
    thresh = cv2.adaptiveThreshold(gray, 255, 
                                  cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                  cv2.THRESH_BINARY_INV, 11, 2)
    
    # Remove small noise
    kernel = np.ones((3,3), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)
    
    # Find contours
    contours, _ = cv2.findContours(cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Calculate pixel-to-unit conversion factor
    pixel_to_unit = reference_length_units / reference_length_pixels
    
    measurements = []
    min_contour_area = 100  # Minimum area to consider as valid object
    
    for contour in contours:
        area = cv2.contourArea(contour)
        if area < min_contour_area:
            continue
            
        # Fit rotated rectangle
        rect = cv2.minAreaRect(contour)
        box = cv2.boxPoints(rect)
        box = np.int32(box)  # Convert to integers for drawing
        
        # Calculate dimensions
        width_px = min(rect[1])
        height_px = max(rect[1])
        
        # Convert to real units
        width_units = width_px * pixel_to_unit
        height_units = height_px * pixel_to_unit
        area_units = area * (pixel_to_unit ** 2)
        
        # Calculate perimeter
        perimeter_px = cv2.arcLength(contour, True)
        perimeter_units = perimeter_px * pixel_to_unit
        
        # Store measurements including bounding box
        measurements.append({
            'width_px': width_px,
            'height_px': height_px,
            'width_units': width_units,
            'height_units': height_units,
            'area_px': area,
            'area_units': area_units,
            'perimeter_px': perimeter_px,
            'perimeter_units': perimeter_units,
            'aspect_ratio': width_px / height_px,
            'centroid': rect[0],
            'bounding_box': box  # Add the bounding box points
        })
    
    return measurements

def draw_measurements(image, measurements):
    """
    Draw measurements on the image.
    
    Args:
        image: Input image
        measurements: List of measurement dictionaries
    Returns:
        Image with measurements drawn
    """
    output = image.copy()
    
    for meas in measurements:
        center = tuple(map(int, meas['centroid']))
        
        # Draw bounding box (now properly defined)
        cv2.drawContours(output, [meas['bounding_box']], 0, (0, 255, 0), 2)
        
        # Draw dimensions
        cv2.putText(output, f"W: {meas['width_units']:.2f} units", 
                   (center[0]+20, center[1]-20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"H: {meas['height_units']:.2f} units", 
                   (center[0]+20, center[1]+0), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
        cv2.putText(output, f"A: {meas['area_units']:.2f} sq.units", 
                   (center[0]+20, center[1]+20), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)
    
    return output








# Perform dimensional analysis (requires a known reference measurement)
reference_length_pixels = 100  # Measure a known object in the image (in pixels)
reference_length_units = 10.0  # The actual length of that object (in cm, inches, etc.)

measurements = dimensional_analysis(undistorted, reference_length_pixels, reference_length_units)

# Draw measurements on the image
measured_image = draw_measurements(undistorted, measurements)

# Display or save the result
cv2.imshow("Measurements", measured_image)
cv2.waitKey(0)
cv2.destroyAllWindows()






def undistort_fisheye_improved(image, strength=0.5, zoom=1.0, balance=0.3, output_shape=None):
    """
    Advanced fisheye undistortion with better quality preservation.
    
    Args:
        image: Input fisheye image (BGR format)
        strength: Distortion correction strength (0.0 to 1.0)
        zoom: Zoom factor (0.8 to 1.5) to adjust output crop
        balance: Balance between linear and nonlinear correction (0.0 to 1.0)
        output_shape: Optional (width, height) tuple for output size
    Returns:
        Undistorted image with preserved quality
    """
    if image is None:
        raise ValueError("Input image is None")
        
    h, w = image.shape[:2]
    
    # Use specified output shape or maintain input dimensions
    if output_shape:
        out_h, out_w = output_shape
    else:
        out_h, out_w = h, w
    
    # Create normalized pixel coordinates in output image space
    x = (np.arange(out_w, dtype=np.float32) - out_w * 0.5
    y = (np.arange(out_h, dtype=np.float32) - out_h * 0.5
    xx, yy = np.meshgrid(x, y)
    
    # Normalize coordinates to [-1, 1] range
    xx_norm = xx / (out_w * 0.5)
    yy_norm = yy / (out_h * 0.5)
    
    # Calculate radial distance with protection against division by zero
    r = np.sqrt(xx_norm**2 + yy_norm**2)
    r = np.clip(r, 1e-8, 1.0)  # Avoid division by zero and extreme values
    
    # Advanced distortion correction formula
    theta = r * (1.0 - strength * 0.5)  # Base correction
    theta = np.where(r > 0.5, 
                    theta * (1.0 + balance * (r - 0.5) * 2),  # Stronger correction at edges
                    theta * (1.0 - balance * (0.5 - r) * 2))  # Gentler correction at center
    
    # Apply zoom factor with edge protection
    zoom_factor = zoom * (1.0 + 0.2 * strength)  # Compensate for edge stretching
    new_x = xx_norm * theta * zoom_factor * (w * 0.5) + (w * 0.5)
    new_y = yy_norm * theta * zoom_factor * (h * 0.5) + (h * 0.5)
    
    # High-quality remapping with multiple interpolation methods
    undistorted = cv2.remap(
        image, 
        new_x.astype(np.float32), 
        new_y.astype(np.float32), 
        interpolation=cv2.INTER_LANCZOS4,
        borderMode=cv2.BORDER_REFLECT101
    )
    
    # Post-processing to enhance quality
    undistorted = cv2.detailEnhance(undistorted, sigma_s=10, sigma_r=0.15)
    
    return undistorted
























Key Objectives:
Undistort using an approximate fisheye model (e.g. stereographic or equisolid).

Preserve resolution and field of view as much as possible.

Enable accurate dimensional analysis later using a known real-world reference object (like a ruler in the image).

üß† Best Strategy Overview:
Use stereographic projection for natural undistortion.

Use a manually specified FOV.

Normalize coordinates to apply distortion correction.

Let the user pass a known object length (e.g., a line in pixels and its real-world length in cm) to calculate pixels-per-cm.

üßæ Code: Undistortion with Post-Hoc Scaling
python
Copy
Edit
import cv2
import numpy as np

def undistort_fisheye_approx(image, model="stereographic", fov_deg=180, zoom=1.0):
    """
    Undistort a fisheye image using an approximate model (stereographic, equisolid, etc.).
    
    Args:
        image (np.ndarray): Input fisheye image (BGR)
        model (str): One of 'stereographic', 'equisolid', 'equidistant'
        fov_deg (float): Horizontal field of view in degrees
        zoom (float): Zoom factor (1.0 = keep original FOV)
    
    Returns:
        Undistorted image (same size), remap_x, remap_y
    """
    h, w = image.shape[:2]
    cx, cy = w / 2, h / 2

    # Normalize coordinates to [-1, 1]
    x = (np.arange(w, dtype=np.float32) - cx) / cx
    y = (np.arange(h, dtype=np.float32) - cy) / cy
    xx, yy = np.meshgrid(x, y)
    r = np.sqrt(xx**2 + yy**2)

    # Convert to angle theta
    theta = r * np.radians(fov_deg / 2)

    # Apply inverse projection model
    if model == "stereographic":
        r_corrected = 2 * np.tan(theta / 2)
    elif model == "equisolid":
        r_corrected = 2 * np.sin(theta / 2)
    elif model == "equidistant":
        r_corrected = theta
    else:
        raise ValueError("Unsupported model: choose stereographic, equisolid, or equidistant")

    # Avoid division by zero
    scale = np.where(r > 1e-8, r_corrected / r, 1.0) * zoom

    map_x = (xx * scale * cx + cx).astype(np.float32)
    map_y = (yy * scale * cy + cy).astype(np.float32)

    # Remap using high-quality interpolation
    undistorted = cv2.remap(image, map_x, map_y, interpolation=cv2.INTER_LANCZOS4, borderMode=cv2.BORDER_REFLECT101)
    return undistorted, map_x, map_y
üìê Step 2: Dimensional Analysis Using Reference Object
python
Copy
Edit
def pixels_per_cm(reference_pixel_length, real_length_cm):
    """
    Calculate pixels per cm from reference object.
    
    Args:
        reference_pixel_length (float): length in pixels
        real_length_cm (float): known real-world length in cm
        
    Returns:
        scale: pixels per cm
    """
    return reference_pixel_length / real_length_cm

def measure_distance(pt1, pt2, px_per_cm):
    """
    Measure real-world distance between two points in cm.
    
    Args:
        pt1, pt2: (x, y) coordinates in pixels
        px_per_cm: pixels per cm scaling factor
        
    Returns:
        distance in cm
    """
    px_dist = np.linalg.norm(np.array(pt1) - np.array(pt2))
    return px_dist / px_per_cm
üõ†Ô∏è How to Use This in Practice
1. Capture Image With Known Object
Place a ruler or object of known size in the image.

2. Run Undistortion
python
Copy
Edit
undistorted, _, _ = undistort_fisheye_approx(image, model="stereographic", fov_deg=180)
3. Mark Reference Points
Use OpenCV cv2.setMouseCallback to mark two endpoints on the known object, or hardcode pixel coordinates.

python
Copy
Edit
reference_length_px = 250  # e.g. pixel distance between 10 cm object
px_per_cm = pixels_per_cm(reference_length_px, 10)
4. Measure in Image
python
Copy
Edit
real_distance = measure_distance((x1, y1), (x2, y2), px_per_cm)
print(f"Measured: {real_distance:.2f} cm")
‚úÖ Why This Works for Your Case
Preserves original resolution and dimensions ‚úÖ

Undistortion removes major fisheye artifacts ‚úÖ

Field of view remains wide enough for coverage ‚úÖ

Dimensional accuracy is achieved via manual calibration (pixels-per-cm) ‚úÖ

Would you like a full working GUI tool where you can:

Select two points on the image

Enter known real-world length

Get real-world measurements from undistorted image?

I can write that for you next.








