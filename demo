import cv2
import torch
import numpy as np
import time
from ultralytics import YOLO
from deep_sort.deep_sort import DeepSort

device = 'cuda' if torch.cuda.is_available() else 'cpu'
model = YOLO('yolov8n.pt')

deepsort = DeepSort("deep_sort/deep_sort/deep/checkpoint/ckpt.t7", use_cuda=torch.cuda.is_available())

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Could not open webcam")
    exit()

cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)

selected_id = None
boxes_param = []

def click_event(event, x, y, flags, param):
    global selected_id
    if event == cv2.EVENT_LBUTTONDOWN:
        for box in param:
            x1, y1, x2, y2, track_id, cls, conf = box
            if x1 <= x <= x2 and y1 <= y <= y2:
                selected_id = track_id
                print(f"Selected object ID {track_id} at ({x}, {y})")
                break

cv2.namedWindow("Object Detection")
cv2.setMouseCallback("Object Detection", click_event, param=[])

prev_time = time.time()

while True:
    ret, frame = cap.read()
    if not ret:
        print("Failed to grab frame")
        break

    input_frame = cv2.resize(frame, (640, 480))

    results = model(input_frame, verbose=False)[0]
    detections = []

    scale_x = frame.shape[1] / input_frame.shape[1]
    scale_y = frame.shape[0] / input_frame.shape[0]

    for r in results.boxes:
        x1, y1, x2, y2 = r.xyxy[0].cpu().numpy()
        conf = float(r.conf[0])
        cls = int(r.cls[0])
        x1, y1, x2, y2 = x1 * scale_x, y1 * scale_y, x2 * scale_x, y2 * scale_y
        w, h = x2 - x1, y2 - y1
        detections.append([x1, y1, w, h, conf])

    if len(detections) > 0:
        dets = np.array(detections)
        outputs = deepsort.update(dets, frame)
    else:
        deepsort.increment_ages()
        outputs = []

    boxes_param = []
    for output in outputs:
        x1, y1, x2, y2, track_id = output
        best_iou, best_cls, best_conf = 0, None, None
        for r in results.boxes:
            rx1, ry1, rx2, ry2 = r.xyxy[0].cpu().numpy()
            rcls, rconf = int(r.cls[0]), float(r.conf[0])
            rx1, ry1, rx2, ry2 = rx1 * scale_x, ry1 * scale_y, rx2 * scale_x, ry2 * scale_y
            inter_x1, inter_y1 = max(x1, rx1), max(y1, ry1)
            inter_x2, inter_y2 = min(x2, rx2), min(y2, ry2)
            inter_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)
            box_area = (rx2 - rx1) * (ry2 - ry1)
            iou = inter_area / box_area if box_area > 0 else 0
            if iou > best_iou:
                best_iou, best_cls, best_conf = iou, rcls, rconf
        if best_iou > 0.3:
            boxes_param.append([int(x1), int(y1), int(x2), int(y2), int(track_id), best_cls, best_conf])

    cv2.setMouseCallback("Object Detection", click_event, param=boxes_param)

    if selected_id is None:
        for box in boxes_param:
            x1, y1, x2, y2, track_id, cls, conf = box
            label = f"ID:{track_id} {model.names[cls]} {conf:.2f}"
            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)
    else:
        found = False
        for box in boxes_param:
            x1, y1, x2, y2, track_id, cls, conf = box
            if track_id == selected_id:
                found = True
                label = f"ID:{track_id} {model.names[cls]} {conf:.2f} [TRACKING]"
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3)
                cv2.putText(frame, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
                break
        if not found:
            pass  # object is out of frame â†’ no box

    current_time = time.time()
    fps = 1 / (current_time - prev_time)
    prev_time = current_time
    cv2.putText(frame, f"FPS: {fps:.1f}", (20, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)

    cv2.imshow("Object Detection", frame)
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break
    elif key == ord('r'):
        selected_id = None

cap.release()
cv2.destroyAllWindows()
